{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcOr5S48+iGaRvQTsqNcM4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"078bac29d92c40248b10befe1adebbd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bf915e020fe459483311ada72508e0f","IPY_MODEL_cb439f80364646ce8713bcd358d83590","IPY_MODEL_be19f3e01c6c4942931794adee2b72d2"],"layout":"IPY_MODEL_cddf0e96a7b44c938c3230936d1f316b"}},"5bf915e020fe459483311ada72508e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e6cd2c3d0cc48b3bb931e79e0d89ab6","placeholder":"​","style":"IPY_MODEL_0559b8dc816942859206c63403088469","value":"config.json: 100%"}},"cb439f80364646ce8713bcd358d83590":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55c5716be7646018a19cddcdabea579","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_265efb22f2844121893d2cb45fe7d126","value":665}},"be19f3e01c6c4942931794adee2b72d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6627383714504d0c9da2b8099fce8ff8","placeholder":"​","style":"IPY_MODEL_6e998d2afd6245a08e7125d62ea818d0","value":" 665/665 [00:00&lt;00:00, 36.3kB/s]"}},"cddf0e96a7b44c938c3230936d1f316b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6cd2c3d0cc48b3bb931e79e0d89ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0559b8dc816942859206c63403088469":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e55c5716be7646018a19cddcdabea579":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"265efb22f2844121893d2cb45fe7d126":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6627383714504d0c9da2b8099fce8ff8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e998d2afd6245a08e7125d62ea818d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f742fcbb6156489285d56012a9b56de7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f9e2d0f3d6642288fa7d7e85dcc41b1","IPY_MODEL_60a1df69d51841d68ad723ed90b16940","IPY_MODEL_d9e6ff7016e24146a6e942f0bf6df314"],"layout":"IPY_MODEL_25acde8ae923416e8d91b7c48fc491f3"}},"9f9e2d0f3d6642288fa7d7e85dcc41b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bc77894ba87417996ce54ea369fd180","placeholder":"​","style":"IPY_MODEL_fc21cfd998824542b82fe8a12f76d63e","value":"model.safetensors:  17%"}},"60a1df69d51841d68ad723ed90b16940":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_255ef77b887a40e4ae043a9f2ca89f51","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1f4aee4b0064cf5ae6b601860fcf2cf","value":94371840}},"d9e6ff7016e24146a6e942f0bf6df314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e0e813c6fe94ceeb92483c5546144ce","placeholder":"​","style":"IPY_MODEL_f6bf47296b2b412ab9a64f5302ee23f7","value":" 94.4M/548M [00:01&lt;00:08, 54.6MB/s]"}},"25acde8ae923416e8d91b7c48fc491f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc77894ba87417996ce54ea369fd180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc21cfd998824542b82fe8a12f76d63e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"255ef77b887a40e4ae043a9f2ca89f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1f4aee4b0064cf5ae6b601860fcf2cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e0e813c6fe94ceeb92483c5546144ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6bf47296b2b412ab9a64f5302ee23f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["##Basic Idea"],"metadata":{"id":"ZpY5ZLqQs4TU"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"Gz7rU_gthP3Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZhyPiQxhLNB","executionInfo":{"status":"ok","timestamp":1700212173830,"user_tz":-330,"elapsed":1724,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}},"outputId":"383d46fd-84b8-458e-96ac-42b612ce4f19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 399.7482\n","Epoch [2/50], Loss: 699.6611\n","Epoch [3/50], Loss: 499.6779\n","Epoch [4/50], Loss: 499.8286\n","Epoch [5/50], Loss: 399.5229\n","Epoch [6/50], Loss: 399.3839\n","Epoch [7/50], Loss: 399.7384\n","Epoch [8/50], Loss: 699.0129\n","Epoch [9/50], Loss: 599.2856\n","Epoch [10/50], Loss: 798.9515\n","Epoch [11/50], Loss: 698.8080\n","Epoch [12/50], Loss: 598.7293\n","Epoch [13/50], Loss: 598.9779\n","Epoch [14/50], Loss: 698.5979\n","Epoch [15/50], Loss: 199.7749\n","Epoch [16/50], Loss: 698.1057\n","Epoch [17/50], Loss: 598.9513\n","Epoch [18/50], Loss: 698.3634\n","Epoch [19/50], Loss: 398.8497\n","Epoch [20/50], Loss: 897.4589\n","Epoch [21/50], Loss: 698.1982\n","Epoch [22/50], Loss: 598.1552\n","Epoch [23/50], Loss: 398.8141\n","Epoch [24/50], Loss: 398.6716\n","Epoch [25/50], Loss: 597.6886\n","Epoch [26/50], Loss: 598.0131\n","Epoch [27/50], Loss: 597.7574\n","Epoch [28/50], Loss: 398.2762\n","Epoch [29/50], Loss: 497.8211\n","Epoch [30/50], Loss: 597.3702\n","Epoch [31/50], Loss: 598.1916\n","Epoch [32/50], Loss: 597.0110\n","Epoch [33/50], Loss: 597.6887\n","Epoch [34/50], Loss: 398.3116\n","Epoch [35/50], Loss: 597.5135\n","Epoch [36/50], Loss: 497.6337\n","Epoch [37/50], Loss: 596.5699\n","Epoch [38/50], Loss: 696.7203\n","Epoch [39/50], Loss: 696.7365\n","Epoch [40/50], Loss: 596.6791\n","Epoch [41/50], Loss: 496.5504\n","Epoch [42/50], Loss: 596.5139\n","Epoch [43/50], Loss: 597.4091\n","Epoch [44/50], Loss: 596.7482\n","Epoch [45/50], Loss: 895.0504\n","Epoch [46/50], Loss: 695.6956\n","Epoch [47/50], Loss: 596.3468\n","Epoch [48/50], Loss: 596.1179\n","Epoch [49/50], Loss: 496.6165\n","Epoch [50/50], Loss: 497.0728\n","Toggle set to \"yes\": tensor([[  -2.7214, -996.6116]], grad_fn=<AddBackward0>)\n","Toggle set to \"no\": tensor([[-1002.7214,     3.3883]], grad_fn=<AddBackward0>)\n"]}],"source":["# Generate a small synthetic dataset\n","torch.manual_seed(42)  # Set seed for reproducibility\n","\n","# Number of samples in the dataset\n","num_samples = 100\n","\n","# Input features (random numbers)\n","X = torch.randn(num_samples, 5)  # 5 input features\n","\n","# Target labels (0 for \"no,\" 1 for \"yes\")\n","y = torch.randint(2, (num_samples,), dtype=torch.long)\n","\n","# Create a DataLoader for the dataset\n","batch_size = 10\n","dataset = TensorDataset(X, y)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Define the neural network model\n","class CustomModel(nn.Module):\n","    def __init__(self, input_size, use_yes_neurons=True):\n","        super(CustomModel, self).__init__()\n","        self.use_yes_neurons = use_yes_neurons\n","        self.fc = nn.Linear(input_size, 2)  # 2 output neurons\n","\n","    def forward(self, x):\n","        if self.use_yes_neurons:\n","            # When using \"yes\" neurons, set the output for \"no\" class to a large negative value\n","            return self.fc(x) + torch.tensor([0.0, -1000.0], device=x.device)\n","        else:\n","            # When using \"no\" neurons, set the output for \"yes\" class to a large negative value\n","            return self.fc(x) + torch.tensor([-1000.0, 0.0], device=x.device)\n","\n","# Instantiate the model with the toggle set to \"yes\" initially\n","model = CustomModel(input_size=5, use_yes_neurons=True)\n","\n","# Define the loss function (cross-entropy loss)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the optimizer (stochastic gradient descent)\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Training loop\n","num_epochs = 50\n","\n","for epoch in range(num_epochs):\n","    for inputs, labels in dataloader:\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Compute the loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print the loss after each epoch\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Now, you can use the trained model with the toggle set to \"yes\" or \"no\"\n","# For example, if toggle is set to \"yes\":\n","# model.use_yes_neurons = True\n","# If toggle is set to \"no\":\n","# model.use_yes_neurons = False\n","\n","# Test the model with some example inputs\n","example_input = torch.randn(1, 5)  # 1 example with 5 input features\n","model.use_yes_neurons = True  # Set the toggle to \"yes\"\n","output_yes = model(example_input)\n","print(f'Toggle set to \"yes\": {output_yes}')\n","\n","model.use_yes_neurons = False  # Set the toggle to \"no\"\n","output_no = model(example_input)\n","print(f'Toggle set to \"no\": {output_no}')\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Define the neural network model\n","class CustomModel(nn.Module):\n","    def __init__(self, input_size, use_yes_neurons=True):\n","        super(CustomModel, self).__init__()\n","        self.use_yes_neurons = use_yes_neurons\n","        self.fc = nn.Linear(input_size, 2)  # 2 output neurons\n","\n","    def forward(self, x):\n","        if self.use_yes_neurons:\n","            # When using \"yes\" neurons, set the output for \"no\" class to a large negative value\n","            return self.fc(x) + torch.tensor([0.0, -1000.0], device=x.device)\n","        else:\n","            # When using \"no\" neurons, set the output for \"yes\" class to a large negative value\n","            return self.fc(x) + torch.tensor([-1000.0, 0.0], device=x.device)\n","\n","# Instantiate the model with the toggle set to \"yes\" initially\n","model = CustomModel(input_size=5, use_yes_neurons=True)\n","\n","# Function to toggle between \"yes\" and \"no\" neurons\n","def toggle_neurons():\n","    model.use_yes_neurons = not model.use_yes_neurons\n","    print(f\"Neurons set to {'yes' if model.use_yes_neurons else 'no'}\")\n","\n","# Chatbot interface\n","print(\"Chatbot Interface - Type 'T' to toggle neurons, 'exit' to quit.\")\n","while True:\n","    user_input = input(\"User: \")\n","\n","    if user_input.lower() == 'exit':\n","        break\n","    elif user_input.lower() == 't':\n","        toggle_neurons()\n","    else:\n","        # Process user input using the model\n","        input_tensor = torch.randn(1, 5)  # Random input for demonstration\n","        model_output = model(input_tensor)\n","        predicted_class = torch.argmax(model_output, dim=1).item()\n","\n","        # Display chatbot response based on the model's prediction\n","        if predicted_class == 0:\n","            print(\"Chatbot: No\")\n","        else:\n","            print(\"Chatbot: Yes\")\n"],"metadata":{"id":"lN5zMT_BhN07"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Basic Idea 2.0"],"metadata":{"id":"yKQXWquLtCzA"}},{"cell_type":"code","source":["# Install the transformers library\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFxUJUF8tB7I","executionInfo":{"status":"ok","timestamp":1700366783247,"user_tz":-330,"elapsed":5486,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}},"outputId":"c34aba28-02eb-411c-85ec-e2541fd1b06d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}]},{"cell_type":"code","source":["import torch\n","import json\n","from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer"],"metadata":{"id":"j87k4JT8xhEG","executionInfo":{"status":"ok","timestamp":1700366790094,"user_tz":-330,"elapsed":6867,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def convert_to_numpy(obj):\n","    if isinstance(obj, torch.Tensor):\n","        return obj.detach().cpu().numpy().tolist()\n","    elif isinstance(obj, dict):\n","        return {key: convert_to_numpy(value) for key, value in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_to_numpy(item) for item in obj]\n","    else:\n","        return obj\n","\n","# Function to save model weights to a file\n","def save_model_weights(model, filename):\n","    torch.save(model.state_dict(), filename)\n","\n","# Function to load model weights from a file\n","def load_model_weights(model, filename):\n","    model.load_state_dict(torch.load(filename))"],"metadata":{"id":"wItZn083xnlM","executionInfo":{"status":"ok","timestamp":1700366790095,"user_tz":-330,"elapsed":13,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Load pre-trained GPT-2 model\n","pretrained_model_name = \"gpt2\"\n","pretrained_model = GPT2LMHeadModel.from_pretrained(pretrained_model_name)\n","\n","#loading pre-trained config to empty model\n","empty_config = GPT2Config.from_dict(pretrained_model.config.to_dict())\n","\n","# Save the state_dict to a JSON file\n","save_model_weights(pretrained_model, \"gpt2_weights.json\")"],"metadata":{"id":"sqpwJjz2jWvB","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["078bac29d92c40248b10befe1adebbd9","5bf915e020fe459483311ada72508e0f","cb439f80364646ce8713bcd358d83590","be19f3e01c6c4942931794adee2b72d2","cddf0e96a7b44c938c3230936d1f316b","0e6cd2c3d0cc48b3bb931e79e0d89ab6","0559b8dc816942859206c63403088469","e55c5716be7646018a19cddcdabea579","265efb22f2844121893d2cb45fe7d126","6627383714504d0c9da2b8099fce8ff8","6e998d2afd6245a08e7125d62ea818d0","f742fcbb6156489285d56012a9b56de7","9f9e2d0f3d6642288fa7d7e85dcc41b1","60a1df69d51841d68ad723ed90b16940","d9e6ff7016e24146a6e942f0bf6df314","25acde8ae923416e8d91b7c48fc491f3","6bc77894ba87417996ce54ea369fd180","fc21cfd998824542b82fe8a12f76d63e","255ef77b887a40e4ae043a9f2ca89f51","e1f4aee4b0064cf5ae6b601860fcf2cf","5e0e813c6fe94ceeb92483c5546144ce","f6bf47296b2b412ab9a64f5302ee23f7"]},"outputId":"d1d93644-1fd7-49ac-d988-a4f3b46f7788"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"078bac29d92c40248b10befe1adebbd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f742fcbb6156489285d56012a9b56de7"}},"metadata":{}}]},{"cell_type":"code","source":["del pretrained_model"],"metadata":{"id":"zH8v1BgRnkBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the state_dict from the JSON file into an empty GPT-2 model\n","empty_model = GPT2LMHeadModel(empty_config)"],"metadata":{"id":"zf67s3u8wSYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import io\n","def load_model_weights_in_chunks(model, filename, chunk_size=1024 * 1024 * 50):  # Adjust the chunk size as needed\n","    with open(filename, \"rb\") as file:\n","        buffer = file.read(chunk_size)\n","        while buffer:\n","            state_dict_chunk = torch.load(io.BytesIO(buffer))\n","            model.load_state_dict(state_dict_chunk, strict=False)\n","            buffer = file.read(chunk_size)\n"],"metadata":{"id":"MQ3ODeLu0w2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_model_weights(empty_model, \"gpt2_weights.json\")\n","\n","# Now, empty_model has the weights and biases from the pre-trained GPT-2 model\n","\n","# Chatbot Interface using the loaded GPT-2 model\n","tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name)"],"metadata":{"id":"Q7766FTzzIs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def chatbot_prompt(prompt, model):\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","\n","    # Generate text\n","    output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n","\n","    # Decode and return the generated text\n","    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return generated_text\n","\n","\n","# Test the chatbot interface\n","user_input = input(\"User: \")\n","while user_input.lower() != 'exit':\n","    chatbot_response = chatbot_prompt(user_input, empty_model)\n","    print(f\"Chatbot: {chatbot_response}\")\n","    user_input = input(\"User: \")"],"metadata":{"id":"MVggMdMbtbMh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unload GPT-2 model weights\n","gpt2_model.reset_parameters()"],"metadata":{"id":"2oU7XzJ86dl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download a sample DALL-E image\n","image_url = \"https://storage.googleapis.com/sfr-vision-language-research/CLIP/demo.jpg\"\n","image = Image.open(requests.get(image_url, stream=True).raw)\n","\n","# Load CLIP model\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model, clip_transform = clip.load(\"ViT-B/32\", device=device)"],"metadata":{"id":"822cj-YG6fXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# Function to generate text based on GPT-2 model\n","def generate_text(prompt, model, tokenizer):\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)\n","    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return generated_text\n","\n","# Function to generate image based on CLIP model\n","def generate_image(prompt, model, transform):\n","    text = clip.tokenize([prompt]).to(device)\n","    image = transform(image).unsqueeze(0).to(device)\n","    similarity = (model.encode_image(image) @ model.encode_text(text)).item()\n","    return similarity\n","\n","# Toggle between the models\n","use_gpt2 = True  # Set to True if using GPT-2, False if using the image generation model\n","\n","if use_gpt2:\n","    # Use GPT-2 model\n","    print(\"Using GPT-2 model\")\n","    gpt2_prompt = \"A conversation about technology and AI.\"\n","    generated_text = generate_text(gpt2_prompt, gpt2_model, gpt2_tokenizer)\n","    print(\"Generated Text:\")\n","    print(generated_text)\n","\n","else:\n","    # Use DALL-E image generation model\n","    print(\"Using CLIP and DALL-E image generation model\")\n","    clip_prompt = \"A surreal image with dreamy colors.\"\n","    similarity = generate_image(clip_prompt, clip_model, clip_transform)\n","    print(\"Similarity Score:\", similarity)\n","    image.show()"],"metadata":{"id":"1sDpu-796Z0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define a simple dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, data_size=50, input_size=5, output_size=10):\n","        self.data = torch.randn(data_size, input_size)\n","        self.labels_text_gen = torch.randn(data_size, output_size)\n","        self.labels_image_gen = torch.randn(data_size, output_size)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels_text_gen[idx], self.labels_image_gen[idx]\n","\n","# Define the model\n","class CustomModel(nn.Module):\n","    def __init__(self, input_size, text_gen_size, image_gen_size):\n","        super(CustomModel, self).__init__()\n","\n","        # Nodes for different tasks\n","        self.text_gen_node = nn.Linear(input_size, text_gen_size)\n","        self.image_gen_node = nn.Linear(input_size, image_gen_size)\n","\n","    def forward(self, input_data, use_text_gen_node):\n","        if use_text_gen_node:\n","            return self.text_gen_node(input_data)\n","        else:\n","            return self.image_gen_node(input_data)\n","\n","# Hyperparameters\n","input_size = 5\n","text_gen_size = 10\n","image_gen_size = 10\n","learning_rate = 0.001\n","num_epochs = 20\n","\n","# Create dataset and dataloader\n","dataset = CustomDataset(data_size=50, input_size=input_size, output_size=max(text_gen_size, image_gen_size))\n","dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n","\n","# Initialize the model\n","model = CustomModel(input_size, text_gen_size, image_gen_size)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    for batch_data, batch_labels_text_gen, batch_labels_image_gen in dataloader:\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        use_text_gen_node = torch.rand(1) > 0.5  # Randomly decide whether to use text_gen_node or image_gen_node\n","        output = model(batch_data, use_text_gen_node)\n","\n","        # Compute the loss\n","        if use_text_gen_node:\n","            loss = criterion(output, batch_labels_text_gen)\n","        else:\n","            loss = criterion(output, batch_labels_image_gen)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print the loss for this epoch\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Example usage\n","input_data_example = torch.randn(1, input_size)\n","output_example = model(input_data_example, use_text_gen_node=True)\n","print(\"Output for text generation node:\", output_example.detach().numpy())\n"],"metadata":{"id":"Rg9J7AxKBVOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install required libraries\n","!pip install torch torchvision transformers tiktoken"],"metadata":{"id":"DXvzSQF9C7wo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from torchvision import transforms\n","from PIL import Image\n","import tiktoken"],"metadata":{"id":"X369gDxODBjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load GPT-2 model and tokenizer\n","model_name = \"gpt2\"  # You can use other GPT-2 variants like \"gpt2-medium\", \"gpt2-large\", etc.\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","# Example text for GPT-2\n","prompt_text = \"Once upon a time in a\"\n","\n","# Tokenize input text\n","input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n","\n","# Generate text\n","output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(\"Generated Text:\")\n","print(generated_text)\n","\n","# Example image generation using torchvision\n","# Note: This is a simple example and may not produce meaningful images\n","transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n","fake_image_data = torch.rand((1, 3, 256, 256))  # Replace this with your actual image data\n","fake_image = transforms.functional.to_pil_image(fake_image_data[0])\n","fake_image.show()\n"],"metadata":{"id":"6SA4peaiBXW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZuARlPVzE9RN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Model, GPT2Config\n","\n","\n","# Define a simple dataset with random data\n","class CustomDataset(Dataset):\n","    def __init__(self, num_samples=100):\n","        self.data = torch.randn(num_samples, 10)  # Replace 10 with appropriate feature size\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# Define the custom model\n","class CustomModel(nn.Module):\n","    def __init__(self, input_size, text_gen_size, image_gen_size, self_training_size, manual_training_size):\n","        super(CustomModel, self).__init__()\n","\n","        # Nodes for different tasks\n","        self.text_gen_node = nn.Linear(in_features=input_size, out_features=text_gen_size)\n","        self.image_gen_node = nn.Linear(in_features=input_size, out_features=image_gen_size)\n","        self.self_training_node = nn.Linear(in_features=input_size, out_features=self_training_size)\n","        self.manual_training_node = nn.Linear(in_features=input_size, out_features=manual_training_size)\n","\n","    def forward(self, input_data, is_self_training, is_manual_training):\n","        # Forward pass through the nodes based on conditions\n","\n","        if is_self_training:\n","            self_training_output = self.self_training_node(input_data)\n","            return self_training_output\n","\n","        if is_manual_training:\n","            manual_training_output = self.manual_training_node(input_data)\n","            return manual_training_output\n","\n","        # Assuming input_data has appropriate features for text or image generation\n","        # For simplicity, let's assume input_data is a tensor for text generation\n","        text_gen_output = self.text_gen_node(input_data)\n","        image_gen_output = self.image_gen_node(input_data)\n","\n","        # Return both text and image generation outputs\n","        return text_gen_output, image_gen_output\n","\n","# Instantiate the model\n","input_size = 10\n","text_gen_size = 10\n","image_gen_size = 10\n","self_training_size = 10\n","manual_training_size = 10\n","\n","custom_model = CustomModel(input_size, text_gen_size, image_gen_size, self_training_size, manual_training_size)\n","\n","# Instantiate the dataset and dataloader\n","dataset = CustomDataset(num_samples=50)\n","dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n","\n","# Define optimizer and criterion\n","optimizer = torch.optim.Adam(custom_model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for batch_data in dataloader:\n","        # Randomly choose whether to self-train or manually train\n","        is_self_training = torch.rand(1) > 0.5\n","        is_manual_training = ~is_self_training\n","\n","        # Forward pass\n","        output = custom_model(batch_data, is_self_training.item(), is_manual_training.item())\n","\n","        # Dummy loss (replace with actual loss computation based on your task)\n","        loss = criterion(output, torch.randn_like(output))\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n","\n","# Generate some random input data for testing\n","test_input = torch.randn(1, input_size)\n","\n","# Test text generation\n","text_gen_output, _ = custom_model(test_input, is_self_training=False, is_manual_training=False)\n","print(f'Text Generation Output: {text_gen_output}')\n","\n","# Test self-training\n","self_training_output = custom_model(test_input, is_self_training=True, is_manual_training=False)\n","print(f'Self-Training Output: {self_training_output}')\n","\n","# Test manual training\n","manual_training_output = custom_model(test_input, is_self_training=False, is_manual_training=True)\n","print(f'Manual Training Output: {manual_training_output}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PkWM5dQCFoH","executionInfo":{"status":"ok","timestamp":1700237948049,"user_tz":-330,"elapsed":696,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}},"outputId":"3a61e73a-1718-4fe6-debf-903c11c3f647"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 1.1144124269485474\n","Epoch [1/10], Loss: 1.8603613376617432\n","Epoch [1/10], Loss: 1.5061668157577515\n","Epoch [1/10], Loss: 1.3230456113815308\n","Epoch [1/10], Loss: 1.1251544952392578\n","Epoch [1/10], Loss: 1.4470881223678589\n","Epoch [1/10], Loss: 1.4572839736938477\n","Epoch [2/10], Loss: 1.5383944511413574\n","Epoch [2/10], Loss: 1.4510440826416016\n","Epoch [2/10], Loss: 1.7896969318389893\n","Epoch [2/10], Loss: 1.527132511138916\n","Epoch [2/10], Loss: 1.8367656469345093\n","Epoch [2/10], Loss: 1.0674484968185425\n","Epoch [2/10], Loss: 1.7676489353179932\n","Epoch [3/10], Loss: 1.6430288553237915\n","Epoch [3/10], Loss: 1.5699056386947632\n","Epoch [3/10], Loss: 1.209604024887085\n","Epoch [3/10], Loss: 1.316046953201294\n","Epoch [3/10], Loss: 1.7769778966903687\n","Epoch [3/10], Loss: 1.5164004564285278\n","Epoch [3/10], Loss: 1.0896966457366943\n","Epoch [4/10], Loss: 1.5018396377563477\n","Epoch [4/10], Loss: 1.3668925762176514\n","Epoch [4/10], Loss: 1.4894083738327026\n","Epoch [4/10], Loss: 0.9686957597732544\n","Epoch [4/10], Loss: 1.2390222549438477\n","Epoch [4/10], Loss: 1.3336291313171387\n","Epoch [4/10], Loss: 1.364558219909668\n","Epoch [5/10], Loss: 1.6164379119873047\n","Epoch [5/10], Loss: 1.4196690320968628\n","Epoch [5/10], Loss: 1.359379529953003\n","Epoch [5/10], Loss: 1.2660752534866333\n","Epoch [5/10], Loss: 1.5125913619995117\n","Epoch [5/10], Loss: 1.0135809183120728\n","Epoch [5/10], Loss: 2.068906307220459\n","Epoch [6/10], Loss: 1.4990346431732178\n","Epoch [6/10], Loss: 0.9052131772041321\n","Epoch [6/10], Loss: 1.6225515604019165\n","Epoch [6/10], Loss: 1.560187578201294\n","Epoch [6/10], Loss: 1.2336381673812866\n","Epoch [6/10], Loss: 1.2459163665771484\n","Epoch [6/10], Loss: 1.8009668588638306\n","Epoch [7/10], Loss: 1.1391605138778687\n","Epoch [7/10], Loss: 1.4719535112380981\n","Epoch [7/10], Loss: 1.7995284795761108\n","Epoch [7/10], Loss: 1.4753401279449463\n","Epoch [7/10], Loss: 1.0137159824371338\n","Epoch [7/10], Loss: 1.5396404266357422\n","Epoch [7/10], Loss: 1.2238590717315674\n","Epoch [8/10], Loss: 1.4391826391220093\n","Epoch [8/10], Loss: 0.9287835955619812\n","Epoch [8/10], Loss: 1.6441090106964111\n","Epoch [8/10], Loss: 1.0760939121246338\n","Epoch [8/10], Loss: 1.3246768712997437\n","Epoch [8/10], Loss: 0.9883555173873901\n","Epoch [8/10], Loss: 1.3843822479248047\n","Epoch [9/10], Loss: 1.2365115880966187\n","Epoch [9/10], Loss: 1.2258825302124023\n","Epoch [9/10], Loss: 1.2958247661590576\n","Epoch [9/10], Loss: 1.362797498703003\n","Epoch [9/10], Loss: 1.2644175291061401\n","Epoch [9/10], Loss: 1.246826410293579\n","Epoch [9/10], Loss: 1.4455044269561768\n","Epoch [10/10], Loss: 1.2037699222564697\n","Epoch [10/10], Loss: 1.5336720943450928\n","Epoch [10/10], Loss: 1.661502480506897\n","Epoch [10/10], Loss: 1.194084644317627\n","Epoch [10/10], Loss: 1.0379278659820557\n","Epoch [10/10], Loss: 1.2479960918426514\n","Epoch [10/10], Loss: 0.80458003282547\n","Text Generation Output: tensor([[ 0.5952,  0.1073, -0.1756,  0.5677, -0.2260, -0.2212, -0.6665,  0.4309,\n","          0.2835,  0.5162]], grad_fn=<AddmmBackward0>)\n","Self-Training Output: tensor([[ 0.2041,  0.1236, -0.7487,  0.0738, -0.4608, -0.0604,  0.0243,  0.0669,\n","         -0.2241, -0.3970]], grad_fn=<AddmmBackward0>)\n","Manual Training Output: tensor([[-0.0580, -0.3238,  0.2273, -0.5407, -0.0699, -0.1509,  0.0488, -0.4844,\n","         -0.0607, -0.3080]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer, GPT2Model\n","#from tiktoken import Tiktoken\n","\n","# Load a pre-trained GPT-2 model and tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","gpt2_model = GPT2Model.from_pretrained(\"gpt2\")\n","\n","# Add a new pad token\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","tokenizer.pad_token = '[PAD]'\n","\n","# Define a custom dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, texts):\n","        self.texts = texts\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        return self.texts[idx]\n","\n","# Define a custom model class\n","class CustomModel(nn.Module):\n","    def __init__(self, gpt2_model):\n","        super(CustomModel, self).__init__()\n","        self.gpt2_model = gpt2_model\n","\n","        # Additional nodes for different tasks can be added here\n","\n","    def forward(self, input_data):\n","        # Assuming input_data is a tensor of tokenized text\n","        gpt2_output = self.gpt2_model(input_data).last_hidden_state\n","        return gpt2_output\n","\n","# Load a small dataset for demonstration purposes\n","texts = [\n","    \"This is the first example sentence.\",\n","    \"Here's another example for testing.\",\n","    \"We need a bit more data for training.\",\n","    \"A small dataset, but good for a demo.\",\n","]\n","\n","# Tokenize the texts using GPT-2 tokenizer\n","tokenized_texts = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","# Instantiate the custom dataset and dataloader\n","dataset = CustomDataset(tokenized_texts[\"input_ids\"])\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n","\n","# Instantiate the custom model\n","custom_model = CustomModel(gpt2_model)\n","\n","# Define optimizer and criterion\n","optimizer = torch.optim.Adam(custom_model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()\n","\n","# Training loop\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    for batch_data in dataloader:\n","        # Assuming input_data is a tensor of tokenized text\n","        input_data = batch_data[\"input_ids\"]\n","\n","        # Forward pass\n","        output = custom_model(input_data)\n","\n","        # Dummy loss (replace with actual loss computation based on your task)\n","        loss = criterion(output, torch.randn_like(output))\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n","\n","# Generate some random input data for testing\n","test_text = \"A test sentence for evaluation.\"\n","\n","# Tokenize the test text\n","tokenized_test_text = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","# Test the custom model\n","test_output = custom_model(tokenized_test_text[\"input_ids\"])\n","print(f'Test Output: {test_output}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"kAx3P6AaEnr7","executionInfo":{"status":"error","timestamp":1700239094456,"user_tz":-330,"elapsed":3279,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}},"outputId":"9ea29d73-9155-4958-c766-f8614c202ed4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-ebc3d40ade13>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Assuming input_data is a tensor of tokenized text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"]}]},{"cell_type":"code","source":["output = custom_model(batch_data[\"input_ids\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181},"id":"vRtcsqWSFOmD","executionInfo":{"status":"error","timestamp":1700238584912,"user_tz":-330,"elapsed":9,"user":{"displayName":"Dhruv Gautam","userId":"09270992311824835089"}},"outputId":"d4512eb9-08bf-44af-b65c-3ccba3affcb6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-eedfe3229d00>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Hj7yW89pHeao"},"execution_count":null,"outputs":[]}]}